{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8ZLZPF0dnLo"
      },
      "source": [
        "# Google Gemini 2.0 with MCP (Model Context Protocol) Servers\n",
        "\n",
        "Gemini models can be used with MCP server using its native tool calling capabilities. MCP, or Model Context Protocol, is an open standard introduced by Anthropic designed to standardize how AI models like Gemini interact with external tools and data sources. Instead of requiring custom integrations for each tool, MCP provides a structured way for models to access context, such as functions (tools), data sources (resources), or pre-defined prompts. This allows AI agents to securely and efficiently connect with real-world systems and workflows.\n",
        "\n",
        "MCP server expose their tools via JSON schema definitions, which can be converted to Gemini compatible OpenAPI schema definitions. This allows you to easily use MCP server with Gemini models, below you will example on how to implement this.\n",
        "\n",
        "You can learn more about Google Search integration with Gemini here:\n",
        "- [https://ai.google.dev/gemini-api/docs/function-calling?lang=python](https://ai.google.dev/gemini-api/docs/function-calling?lang=python&example=weather)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R08lmeGPdnLq"
      },
      "outputs": [],
      "source": [
        "# install Google GenAI and MCP\n",
        "%pip install google-genai mcp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TutEcng_dnLr"
      },
      "source": [
        "## Simple Example on how to use MCP with Gemini's tool calling\n",
        "\n",
        "MCPs can be used with Google DeepMind Gemini by converting the MCP tools into Gemini compatible tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W86On0lBdnLs",
        "outputId": "55a867c4-14fe-477a-9b56-f2c6235e4061"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnsupportedOperation",
          "evalue": "fileno",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0e5f79ffc5d0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-0e5f79ffc5d0>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstdio_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         async with ClientSession(\n\u001b[1;32m     28\u001b[0m             \u001b[0mread\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0manext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopAsyncIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mcp/client/stdio/__init__.py\u001b[0m in \u001b[0;36mstdio_client\u001b[0;34m(server, errlog)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Open process with stderr piped for capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     process = await _create_platform_compatible_process(\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mcp/client/stdio/__init__.py\u001b[0m in \u001b[0;36m_create_platform_compatible_process\u001b[0;34m(command, args, env, errlog, cwd)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcreate_windows_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         process = await anyio.open_process(\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anyio/_core/_subprocesses.py\u001b[0m in \u001b[0;36mopen_process\u001b[0;34m(command, stdin, stdout, stderr, cwd, env, startupinfo, creationflags, start_new_session, pass_fds, user, group, extra_groups, umask)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"umask\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     return await get_async_backend().open_process(\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\u001b[0m in \u001b[0;36mopen_process\u001b[0;34m(cls, command, stdin, stdout, stderr, **kwargs)\u001b[0m\n\u001b[1;32m   2559\u001b[0m             )\n\u001b[1;32m   2560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m             process = await asyncio.create_subprocess_exec(\n\u001b[0m\u001b[1;32m   2562\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m                 \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/subprocess.py\u001b[0m in \u001b[0;36mcreate_subprocess_exec\u001b[0;34m(program, stdin, stdout, stderr, limit, *args, **kwds)\u001b[0m\n\u001b[1;32m    221\u001b[0m     protocol_factory = lambda: SubprocessStreamProtocol(limit=limit,\n\u001b[1;32m    222\u001b[0m                                                         loop=loop)\n\u001b[0;32m--> 223\u001b[0;31m     transport, protocol = await loop.subprocess_exec(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mprotocol_factory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mprogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/base_events.py\u001b[0m in \u001b[0;36msubprocess_exec\u001b[0;34m(self, protocol_factory, program, stdin, stdout, stderr, universal_newlines, shell, bufsize, encoding, errors, text, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1706\u001b[0m             \u001b[0mdebug_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'execute program {program!r}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_subprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         transport = await self._make_subprocess_transport(\n\u001b[0m\u001b[1;32m   1709\u001b[0m             \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopen_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             bufsize, **kwargs)\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/unix_events.py\u001b[0m in \u001b[0;36m_make_subprocess_transport\u001b[0;34m(self, protocol, args, shell, stdin, stdout, stderr, bufsize, extra, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                    \"subprocess support is not installed.\")\n\u001b[1;32m    206\u001b[0m             \u001b[0mwaiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             transp = _UnixSubprocessTransport(self, protocol, args, shell,\n\u001b[0m\u001b[1;32m    208\u001b[0m                                               \u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                                               \u001b[0mwaiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwaiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/base_subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loop, protocol, args, shell, stdin, stdout, stderr, bufsize, waiter, extra, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Create the child process: set the _proc attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             self._start(args=args, shell=shell, stdin=stdin, stdout=stdout,\n\u001b[0m\u001b[1;32m     37\u001b[0m                         stderr=stderr, bufsize=bufsize, **kwargs)\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/unix_events.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, args, shell, stdin, stdout, stderr, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocketpair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m             self._proc = subprocess.Popen(\n\u001b[0m\u001b[1;32m    819\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                 universal_newlines=False, bufsize=bufsize, **kwargs)\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m    990\u001b[0m         (p2cread, p2cwrite,\n\u001b[1;32m    991\u001b[0m          \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m          errread, errwrite) = self._get_handles(stdin, stdout, stderr)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;31m# From here on, raising exceptions may cause file descriptor leakage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_get_handles\u001b[0;34m(self, stdin, stdout, stderr)\u001b[0m\n\u001b[1;32m   1743\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                     \u001b[0;31m# Assuming file-like object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m                     \u001b[0merrwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m             return (p2cread, p2cwrite,\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mfileno\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_stdstream_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fileno\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_watch_pipe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnsupportedOperation\u001b[0m: fileno"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=\"AIzaSyDvg2F_x1TMDOTnFdhGxEv5R6CD2oJHaR4\"\n",
        ")  # Replace with your actual API key setup\n",
        "\n",
        "\n",
        "# Create server parameters for stdio connection\n",
        "server_params = StdioServerParameters(\n",
        "    command=\"npx\",  # Executable\n",
        "    args=[\n",
        "        \"-y\",\n",
        "        \"@openbnb/mcp-server-airbnb\",\n",
        "        \"--ignore-robots-txt\",\n",
        "    ],  # Optional command line arguments\n",
        "    env=None,  # Optional environment variables\n",
        ")\n",
        "\n",
        "async def run():\n",
        "    async with stdio_client(server_params) as (read, write):\n",
        "        async with ClientSession(\n",
        "            read,\n",
        "            write,\n",
        "        ) as session:\n",
        "            prompt = \"I want to book an apartment in Paris for 2 nights. 03/28 - 03/30\"\n",
        "            # Initialize the connection\n",
        "            await session.initialize()\n",
        "\n",
        "            # Get tools from MCP session and convert to Gemini Tool objects\n",
        "            mcp_tools = await session.list_tools()\n",
        "            tools = types.Tool(function_declarations=[\n",
        "                {\n",
        "                    \"name\": tool.name,\n",
        "                    \"description\": tool.description,\n",
        "                    \"parameters\": tool.inputSchema,\n",
        "                }\n",
        "                for tool in mcp_tools.tools\n",
        "            ])\n",
        "\n",
        "            # Send request with function declarations\n",
        "            response = client.models.generate_content(\n",
        "                model=\"gemini-2.0-flash\",  # Or your preferred model supporting function calling\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                    temperature=0.7,\n",
        "                    tools=[tools],\n",
        "                ),  # Example other config\n",
        "            )\n",
        "        # Check for a function call\n",
        "        if response.candidates[0].content.parts[0].function_call:\n",
        "            function_call = response.candidates[0].content.parts[0].function_call\n",
        "            print(f\"Function to call: {function_call.name}\")\n",
        "            print(f\"Arguments: {function_call.args}\")\n",
        "            # In a real app, you would call your function here:\n",
        "            # result = await session.call_tool(function_call.args, arguments=function_call.args)\n",
        "            # sent new request with function call\n",
        "        else:\n",
        "            print(\"No function call found in the response.\")\n",
        "            print(response.text)\n",
        "\n",
        "await run()\n"
      ]
    },
    {
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "import sys\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=\"AIzaSyDvg2F_x1TMDOTnFdhGxEv5R6CD2oJHaR4\"\n",
        ")  # Replace with your actual API key setup\n",
        "\n",
        "\n",
        "# Create server parameters for stdio connection\n",
        "server_params = StdioServerParameters(\n",
        "    command=\"npx\",  # Executable\n",
        "    args=[\n",
        "        \"-y\",\n",
        "        \"@openbnb/mcp-server-airbnb\",\n",
        "        \"--ignore-robots-txt\",\n",
        "    ],  # Optional command line arguments\n",
        "    env=None,  # Optional environment variables\n",
        ")\n",
        "\n",
        "async def run():\n",
        "    # Instead of redirecting stderr to a file, use asyncio.subprocess.PIPE\n",
        "    async with stdio_client(server_params, errlog=asyncio.subprocess.PIPE) as (read, write):\n",
        "        async with ClientSession(\n",
        "            read,\n",
        "            write,\n",
        "        ) as session:\n",
        "            prompt = \"I want to book an apartment in Paris for 2 nights. 03/28 - 03/30\"\n",
        "            # Initialize the connection\n",
        "            await session.initialize()\n",
        "\n",
        "            # Get tools from MCP session and convert to Gemini Tool objects\n",
        "            mcp_tools = await session.list_tools()\n",
        "            tools = types.Tool(function_declarations=[\n",
        "                {\n",
        "                    \"name\": tool.name,\n",
        "                    \"description\": tool.description,\n",
        "                    \"parameters\": tool.inputSchema,\n",
        "                }\n",
        "                for tool in mcp_tools.tools\n",
        "            ])\n",
        "\n",
        "            # Send request with function declarations\n",
        "            response = client.models.generate_content(\n",
        "                model=\"gemini-2.0-flash\",  # Or your preferred model supporting function calling\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                    temperature=0.7,\n",
        "                    tools=[tools],\n",
        "                ),  # Example other config\n",
        "            )\n",
        "        # Check for a function call\n",
        "        if response.candidates[0].content.parts[0].function_call:\n",
        "            function_call = response.candidates[0].content.parts[0].function_call\n",
        "            print(f\"Function to call: {function_call.name}\")\n",
        "            print(f\"Arguments: {function_call.args}\")\n",
        "            # In a real app, you would call your function here:\n",
        "            # result = await session.call_tool(function_call.args, arguments=function_call.args)\n",
        "            # sent new request with function call\n",
        "        else:\n",
        "            print(\"No function call found in the response.\")\n",
        "            print(response.text)\n",
        "\n",
        "\n",
        "# Because this is an async function and in a Jupyter notebook, you need to use\n",
        "# asyncio.run or asyncio.create_task to ensure it runs and completes correctly.\n",
        "asyncio.run(run())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "twPqdJP7MCWR",
        "outputId": "edbe1503-3cae-4425-ad80-3b81f16585a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3b12adb4f2f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Because this is an async function and in a Jupyter notebook, you need to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# asyncio.run or asyncio.create_task to ensure it runs and completes correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# fail fast with short traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "import sys\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=\"AIzaSyDvg2F_x1TMDOTnFdhGxEv5R6CD2oJHaR4\"\n",
        ")  # Replace with your actual API key setup\n",
        "\n",
        "\n",
        "# Create server parameters for stdio connection\n",
        "server_params = StdioServerParameters(\n",
        "    command=\"npx\",  # Executable\n",
        "    args=[\n",
        "        \"-y\",\n",
        "        \"@openbnb/mcp-server-airbnb\",\n",
        "        \"--ignore-robots-txt\",\n",
        "    ],  # Optional command line arguments\n",
        "    env=None,  # Optional environment variables\n",
        ")\n",
        "\n",
        "async def run():\n",
        "    # Instead of redirecting stderr to a file, use asyncio.subprocess.PIPE\n",
        "    async with stdio_client(server_params, errlog=asyncio.subprocess.PIPE) as (read, write):\n",
        "        async with ClientSession(\n",
        "            read,\n",
        "            write,\n",
        "        ) as session:\n",
        "            prompt = \"I want to book an apartment in Paris for 2 nights. 03/28 - 03/30\"\n",
        "            # Initialize the connection\n",
        "            await session.initialize()\n",
        "\n",
        "            # Get tools from MCP session and convert to Gemini Tool objects\n",
        "            mcp_tools = await session.list_tools()\n",
        "            tools = types.Tool(function_declarations=[\n",
        "                {\n",
        "                    \"name\": tool.name,\n",
        "                    \"description\": tool.description,\n",
        "                    \"parameters\": tool.inputSchema,\n",
        "                }\n",
        "                for tool in mcp_tools.tools\n",
        "            ])\n",
        "\n",
        "            # Send request with function declarations\n",
        "            response = client.models.generate_content(\n",
        "                model=\"gemini-2.0-flash\",  # Or your preferred model supporting function calling\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                    temperature=0.7,\n",
        "                    tools=[tools],\n",
        "                ),  # Example other config\n",
        "            )\n",
        "        # Check for a function call\n",
        "        if response.candidates[0].content.parts[0].function_call:\n",
        "            function_call = response.candidates[0].content.parts[0].function_call\n",
        "            print(f\"Function to call: {function_call.name}\")\n",
        "            print(f\"Arguments: {function_call.args}\")\n",
        "            # In a real app, you would call your function here:\n",
        "            # result = await session.call_tool(function_call.args, arguments=function_call.args)\n",
        "            # sent new request with function call\n",
        "        else:\n",
        "            print(\"No function call found in the response.\")\n",
        "            print(response.text)\n",
        "\n",
        "\n",
        "# Because this is an async function and in a Jupyter notebook, you need to use\n",
        "# asyncio.run or asyncio.create_task to ensure it runs and completes correctly.\n",
        "# Instead of asyncio.run, use asyncio.create_task and await it\n",
        "# or use IPython.display.display(asyncio.create_task(run())) to display the task\n",
        "await run()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CKq5Lv-QMNfP",
        "outputId": "b351c367-29a8-4260-aa9f-f365b26a3af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function to call: airbnb_search\n",
            "Arguments: {'location': 'Paris', 'checkout': '2024-03-30', 'checkin': '2024-03-28'}\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "import sys\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=os.getenv(\"GEMINI_API_KEY\")\n",
        ")  # Replace with your actual API key setup\n",
        "\n",
        "\n",
        "# Create server parameters for stdio connection\n",
        "server_params = StdioServerParameters(\n",
        "    command=\"npx\",  # Executable\n",
        "    args=[\n",
        "        \"-y\",\n",
        "        \"@openbnb/mcp-server-airbnb\",\n",
        "        \"--ignore-robots-txt\",\n",
        "    ],  # Optional command line arguments\n",
        "    env=None,  # Optional environment variables\n",
        ")\n",
        "\n",
        "async def run():\n",
        "    # Redirect stderr to a file\n",
        "    with open('stderr.log', 'w') as stderr_file:\n",
        "        # Set sys.stderr to the file\n",
        "        original_stderr = sys.stderr\n",
        "        sys.stderr = stderr_file\n",
        "\n",
        "        async with stdio_client(server_params, errlog=stderr_file) as (read, write):\n",
        "            async with ClientSession(\n",
        "                read,\n",
        "                write,\n",
        "            ) as session:\n",
        "                prompt = \"I want to book an apartment in Paris for 2 nights. 03/28 - 03/30\"\n",
        "                # Initialize the connection\n",
        "                await session.initialize()\n",
        "\n",
        "                # Get tools from MCP session and convert to Gemini Tool objects\n",
        "                mcp_tools = await session.list_tools()\n",
        "                tools = types.Tool(function_declarations=[\n",
        "                    {\n",
        "                        \"name\": tool.name,\n",
        "                        \"description\": tool.description,\n",
        "                        \"parameters\": tool.inputSchema,\n",
        "                    }\n",
        "                    for tool in mcp_tools.tools\n",
        "                ])\n",
        "\n",
        "                # Send request with function declarations\n",
        "                response = client.models.generate_content(\n",
        "                    model=\"gemini-2.0-flash\",  # Or your preferred model supporting function calling\n",
        "                    contents=prompt,\n",
        "                    config=types.GenerateContentConfig(\n",
        "                        temperature=0.7,\n",
        "                        tools=[tools],\n",
        "                    ),  # Example other config\n",
        "                )\n",
        "            # Check for a function call\n",
        "            if response.candidates[0].content.parts[0].function_call:\n",
        "                function_call = response.candidates[0].content.parts[0].function_call\n",
        "                print(f\"Function to call: {function_call.name}\")\n",
        "                print(f\"Arguments: {function_call.args}\")\n",
        "                # In a real app, you would call your function here:\n",
        "                # result = await session.call_tool(function_call.args, arguments=function_call.args)\n",
        "                # sent new request with function call\n",
        "            else:\n",
        "                print(\"No function call found in the response.\")\n",
        "                print(response.text)\n",
        "\n",
        "    # Restore the original stderr\n",
        "    sys.stderr = original_stderr\n",
        "\n",
        "# Because this is an async function and in a Jupyter notebook, you need to use\n",
        "# asyncio.run or asyncio.create_task to ensure it runs and completes correctly.\n",
        "asyncio.run(run())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1yBXcOEUeiqK",
        "outputId": "01cda5a5-cacb-4426-edde-9887c0432cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-59d04a994f30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Because this is an async function and in a Jupyter notebook, you need to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# asyncio.run or asyncio.create_task to ensure it runs and completes correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# fail fast with short traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpPzA1ekdnLs"
      },
      "source": [
        "## Full Agentic example with Gemini and Airbnb MCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAZwyvL6dnLt",
        "outputId": "bdd99d93-9101-42ac-b342-9acb623d3580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running agent loop with prompt: I want to book an apartment in Paris for 2 nights. 03/28 - 03/30\n",
            "Attempting to call MCP tool: 'airbnb_search' with args: {'checkout': '2024-03-30', 'checkin': '2024-03-28', 'location': 'Paris'}\n",
            "MCP tool 'airbnb_search' executed successfully.\n",
            "Added 1 tool response parts to history.\n",
            "Making subsequent API call with tool responses...\n",
            "MCP tool calling loop finished. Returning final response.\n",
            "OK. I have searched for apartments in Paris for 2 nights from 2024-03-28 to 2024-03-30. Here are some of the results:\n",
            "* Room in Paris: https://www.airbnb.com/rooms/1192814572435529819\n",
            "* Room with balcony very close to Paris: https://www.airbnb.com/rooms/1073307779802809893\n",
            "* Small charming two-room in the middle of the courtyard: https://www.airbnb.com/rooms/51646829\n",
            "* A room 30 minutes from Paris with the RER C. tram9: https://www.airbnb.com/rooms/16219327\n",
            "* Le Voyage Paris: https://www.airbnb.com/rooms/1236913077555360681\n",
            "* Small Functional Studio: https://www.airbnb.com/rooms/1314305750209848961\n",
            "* Lovely little duplex house: https://www.airbnb.com/rooms/3599795\n",
            "* Cozy & Bright Parisian Style - 2P - Metro 400m: https://www.airbnb.com/rooms/1338982550925585307\n",
            "* Charming studio in the heart of the 14th arrondissement in Paris: https://www.airbnb.com/rooms/1161505367060701505\n",
            "* Service room 9 m2 , Trocadéro: https://www.airbnb.com/rooms/11137901\n",
            "* Very quiet 13 m² studio: https://www.airbnb.com/rooms/1058613505664263800\n",
            "* Luxembourg Gardens Room-Suite: https://www.airbnb.com/rooms/1348422275502236977\n",
            "* Charming Marais/Bastille studio: https://www.airbnb.com/rooms/1121566618691941945\n",
            "* ☀️ Cosy studio close to the Buttes Chaumont: https://www.airbnb.com/rooms/25961524\n",
            "* Bedroom 1 in charming Parisian house: https://www.airbnb.com/rooms/10625291\n",
            "* Room with balcony at Mairie de Montreuil: https://www.airbnb.com/rooms/596094203335263543\n",
            "* A very bright room/balcony: https://www.airbnb.com/rooms/8436272\n",
            "* Nice room in 3 rooms in Ménilmontant 3 cats: https://www.airbnb.com/rooms/15532830\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "model = \"gemini-2.0-flash\"\n",
        "\n",
        "# Create server parameters for stdio connection\n",
        "server_params = StdioServerParameters(\n",
        "    command=\"npx\",  # Executable\n",
        "    args=[\n",
        "        \"-y\",\n",
        "        \"@openbnb/mcp-server-airbnb\",\n",
        "        \"--ignore-robots-txt\",\n",
        "    ],  # Optional command line arguments\n",
        "    env=None,  # Optional environment variables\n",
        ")\n",
        "\n",
        "async def agent_loop(prompt: str, client: genai.Client, session: ClientSession):\n",
        "    contents = [types.Content(role=\"user\", parts=[types.Part(text=prompt)])]\n",
        "    # Initialize the connection\n",
        "    await session.initialize()\n",
        "\n",
        "    # --- 1. Get Tools from Session and convert to Gemini Tool objects ---\n",
        "    mcp_tools = await session.list_tools()\n",
        "    tools = types.Tool(function_declarations=[\n",
        "        {\n",
        "            \"name\": tool.name,\n",
        "            \"description\": tool.description,\n",
        "            \"parameters\": tool.inputSchema,\n",
        "        }\n",
        "        for tool in mcp_tools.tools\n",
        "    ])\n",
        "\n",
        "    # --- 2. Initial Request with user prompt and function declarations ---\n",
        "    response = await client.aio.models.generate_content(\n",
        "        model=model,  # Or your preferred model supporting function calling\n",
        "        contents=contents,\n",
        "        config=types.GenerateContentConfig(\n",
        "            temperature=0,\n",
        "            tools=[tools],\n",
        "        ),  # Example other config\n",
        "    )\n",
        "\n",
        "    # --- 3. Append initial response to contents ---\n",
        "    contents.append(response.candidates[0].content)\n",
        "\n",
        "    # --- 4. Tool Calling Loop ---\n",
        "    turn_count = 0\n",
        "    max_tool_turns = 5\n",
        "    while response.function_calls and turn_count < max_tool_turns:\n",
        "        turn_count += 1\n",
        "        tool_response_parts: List[types.Part] = []\n",
        "\n",
        "        # --- 4.1 Process all function calls in order and return in this turn ---\n",
        "        for fc_part in response.function_calls:\n",
        "            tool_name = fc_part.name\n",
        "            args = fc_part.args or {}  # Ensure args is a dict\n",
        "            print(f\"Attempting to call MCP tool: '{tool_name}' with args: {args}\")\n",
        "\n",
        "            tool_response: dict\n",
        "            try:\n",
        "                # Call the session's tool executor\n",
        "                tool_result = await session.call_tool(tool_name, args)\n",
        "                print(f\"MCP tool '{tool_name}' executed successfully.\")\n",
        "                if tool_result.isError:\n",
        "                    tool_response = {\"error\": tool_result.content[0].text}\n",
        "                else:\n",
        "                    tool_response = {\"result\": tool_result.content[0].text}\n",
        "            except Exception as e:\n",
        "                tool_response = {\"error\":  f\"Tool execution failed: {type(e).__name__}: {e}\"}\n",
        "\n",
        "            # Prepare FunctionResponse Part\n",
        "            tool_response_parts.append(\n",
        "                types.Part.from_function_response(\n",
        "                    name=tool_name, response=tool_response\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # --- 4.2 Add the tool response(s) to history ---\n",
        "        contents.append(types.Content(role=\"user\", parts=tool_response_parts))\n",
        "        print(f\"Added {len(tool_response_parts)} tool response parts to history.\")\n",
        "\n",
        "        # --- 4.3 Make the next call to the model with updated history ---\n",
        "        print(\"Making subsequent API call with tool responses...\")\n",
        "        response = await client.aio.models.generate_content(\n",
        "            model=model,\n",
        "            contents=contents,  # Send updated history\n",
        "            config=types.GenerateContentConfig(\n",
        "                temperature=1.0,\n",
        "                tools=[tools],\n",
        "            ),  # Keep sending same config\n",
        "        )\n",
        "        contents.append(response.candidates[0].content)\n",
        "\n",
        "    if turn_count >= max_tool_turns and response.function_calls:\n",
        "        print(f\"Maximum tool turns ({max_tool_turns}) reached. Exiting loop.\")\n",
        "\n",
        "    print(\"MCP tool calling loop finished. Returning final response.\")\n",
        "    # --- 5. Return Final Response ---\n",
        "    return response\n",
        "\n",
        "async def run():\n",
        "    async with stdio_client(server_params) as (read, write):\n",
        "        async with ClientSession(\n",
        "            read,\n",
        "            write,\n",
        "        ) as session:\n",
        "            # Test prompt\n",
        "            prompt = \"I want to book an apartment in Paris for 2 nights. 03/28 - 03/30\"\n",
        "            print(f\"Running agent loop with prompt: {prompt}\")\n",
        "            # Run agent loop\n",
        "            res = await agent_loop(prompt, client, session)\n",
        "            return res\n",
        "res = await run()\n",
        "print(res.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY62Lh-TdnLt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}